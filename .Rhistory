pValues[i] = summary(lm(y ~ x))$coef[2,4]
}
a <- 0.1
aFWER <- 0.1/length(pValues)
pSignificant <- pValues < aFWER
sum(pSignificant)
pOrder <- sort(pValues)
pSignificant2 <- rep(NA,100)
for(i in 1:100){
pSignificant2[i] <- pOrder[i] <= a*i/length(pValues)
}
sum(pSignificant2)
sum(pValues)
sum(pValues<a)
set.seed(42)
xm <- rnorm(1000)
em <- rnorm(1000)
b0 <- 1
b1 <- 2
ym <- rep(b0,100)+rnorm(1000,mean=rep(b1,1000)*x)+e
set.seed(42)
xm <- rnorm(1000)
em <- rnorm(1000)
b0 <- 1
b1 <- 2
ym <- rep(b0,100)+rnorm(1000,mean=rep(b1,1000)*x)+em
summary(lm(ym~xm))
ym <- rep(b0,100)+rep(b1,1000)*rnorm(1000,mean=x)+em
summary(lm(ym~xm))
set.seed(42)
xm <- rnorm(1000)
em <- rnorm(1000)
b0 <- 1
b1 <- 2
ym <- rep(b0,100)+rep(b1,1000)*rnorm(1000,mean=xm)+em
summary(lm(ym~xm))
?which
?quantile
?percentile
quantile(xm)
quantile(xm,0.9)
xm2 <- (xm<=quantile(xm,0.9))*xm
fix(xm2)
xm2 <- rep(NA,1000)
for(i in 1:1000){
if(xm[i]<=quantile(xm,0.9)){
xm2[i] <- xm[i]
}
}
fix(xm2)
summary(lm(ym~xm2))
ym2 <- rep(NA,1000)
for(i in 1:1000){
if(ym[i]<=quantile(ym,0.9)){
ym2[i] <- ym[i]
}
}
summary(lm(ym2~xm))
library("MASS", lib.loc="/Library/Frameworks/R.framework/Versions/2.15/Resources/library")
fix(pSignificant2)
summary(rlm(ym~xm))
summary(rlm(ym~xm2))
summary(rlm(ym2~xm))
install.packages("KernSmooth")
library("KernSmooth", lib.loc="/Library/Frameworks/R.framework/Versions/2.15/Resources/library")
install.packages(c("ape", "bigmemory", "bitops", "cluster", "digest", "e1071", "evaluate", "foreign", "igraph", "igraphdata", "KernSmooth", "lattice", "mgcv", "nnet", "R.matlab", "R.methodsS3", "R.oo", "R.utils", "rgl", "rpart", "SparseM", "survival", "tree", "whisker"))
devtools::install_github("hadley/httr")
library("devtools", lib.loc="/Library/Frameworks/R.framework/Versions/2.15/Resources/library")
install("/Users/carlis/Downloads/httr-0.3")
install.packages(c("ape", "BH", "devtools", "evaluate", "VGAM"))
install.packages("httr")
library("httr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages(RCurl)
install.packages("RCurl")
library("httr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("stringr")
library("httr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("igraph", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.package("igraph")
install.packages("igraph")
update.packages(checkBuilt=TRUE)
y
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. Register an application at https://github.com/settings/applications
#    Insert your values below - if secret is omitted, it will look it up in
#    the GITHUB_CONSUMER_SECRET environmental variable.
#
#    Use http://localhost:1410 as the callback url
myapp <- oauth_app("github", "e60b67ff1191f9930b58", "b782cc14e75ffec27c14680729aaaaadc6911692")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
clear
cls
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?panel.lmline
?trellis.par.set
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + geom_smooth(method="loess")
qplot(votes, rating, data = movies, smooth = "lm")
qplot(votes, rating, data = movies) + geom_smooth()
install.packages("caret")
install.packages("SSOAP")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
update.packages(checkBuilt=TRUE)
install.package("SSOAP", repos="http://www.omegahat.org/R", dpendencies=TRUE, type="source")
install.packages("SSOAP", repos="http://www.omegahat.org/R", dpendencies=TRUE, type="source")
install.packages("XML")
install.packages("XMLSchema")
install.packages("XMLSchema", type="source")
install.packages("SSOAP", repos="http://www.omegahat.org/R", dpendencies=TRUE, type="source")
?install.packages
install.packages("XMLSchema", repos="http://www.omegahat.org/R", dpendencies=TRUE, type="source")
install.packages("XMLSchema", repos="http://www.omegahat.org/R", type="source")
install.packages("SSOAP", repos="http://www.omegahat.org/R", dpendencies=TRUE, type="source")
install.packages("SSOAP", repos="http://www.omegahat.org/R", type="source")
install.packages("lubridate")
library(SSOAP)
library(lubridate)
library(ggplot2)
library(scales)
library(manipulate)
xrate.asmx <- processWSDL("http://banguat.gob.gt/variables/ws/TipoCambio.asmx?WSDL")
xrate.interface <- genSOAPClientInterface(xrate.asmx@operations[[1]], def = xrate.asmx, xrate.asmx@name, verbose=T)
out <- xrate.interface@functions$TipoCambioFechaInicial("01/01/2000")
records <- out@TotalItems
xrate <- data.frame(fecha=rep("",records),venta=rep(NA,records),compra=rep(NA,records),referencia=rep(NA,records),stringsAsFactors=FALSE)
for (i in 1:records){
xrate[i,1] <- out@Vars[[i]]@fecha
xrate[i,2] <- out@Vars[[i]]@venta
xrate[i,3] <- out@Vars[[i]]@compra
xrate[i,4] <- (out@Vars[[i]]@venta + out@Vars[[i]]@compra)/2
}
xrate$fecha <- dmy(xrate$fecha)
xrate$year <- as.factor(year(xrate$fecha))
xrate$fecha2 <- ymd(paste0("2000",substr(as.character(xrate$fecha),5,10)))
manipulate({
ggplot(xrate[as.numeric(as.character(xrate$year)) %in% c(2000:2014)[c(cb00, cb01, cb02, cb03, cb04, cb05, cb06, cb07, cb08, cb09, cb10, cb11, cb12, cb13, cb14)],], aes(fecha2, referencia, group=year)) +
geom_line(aes(colour=year)) + scale_colour_hue(l=45) +
labs(x="", y="Tipo de Cambio, Q/US$") +
scale_x_datetime(labels = date_format("%b"), breaks = date_breaks("months"))},
cb00 = checkbox(FALSE, "2000"),
cb01 = checkbox(FALSE, "2001"),
cb02 = checkbox(FALSE, "2002"),
cb03 = checkbox(FALSE, "2003"),
cb04 = checkbox(FALSE, "2004"),
cb05 = checkbox(FALSE, "2005"),
cb06 = checkbox(FALSE, "2006"),
cb07 = checkbox(FALSE, "2007"),
cb08 = checkbox(FALSE, "2008"),
cb09 = checkbox(FALSE, "2009"),
cb10 = checkbox(FALSE, "2010"),
cb11 = checkbox(TRUE, "2011"),
cb12 = checkbox(TRUE, "2012"),
cb13 = checkbox(TRUE, "2013"),
cb14 = checkbox(TRUE, "2014")
)
xrate[seq(records-5,records),c(1,4)]
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
set.seed(125)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p =0.7, list=FALSE)
View(inTrain)
training <- segmentationOriginal[inTrain]
testing <- segmentationOriginal[-inTrain]
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
ModelQ1 <- train(Case~., data=training, method = "rpart")
?predict
DataA <- data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2)
DataB <- data.frame(TotalIntench2 = 50000, FiberWidthCh1 = 10, VarIntenCh4 = 100)
DataC <- data.frame(TotalIntench2 = 57000, FiberWidthCh1 = 8, VarIntenCh4 = 100)
DataD <- data.frame(FiberWidthCh1 = 8, VarIntenCh4 = 100, PerimStatusCh1=2)
predict(ModelQ1, DataA)
DataA <- data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2, Cell =NA)
predict(ModelQ1, DataA)
training <- segmentationOriginal[Case == "Train",]
testing <- segmentationOriginal[Case == "Test",]
set.seed(125)
ModelQ1 <- train(Class~., data=training, method = "rpart")
training <- segmentationOriginal[segmentationOriginal$Case == "Train",]
testing <- segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
ModelQ1 <- train(Class~., data=training, method = "rpart")
DataA <- data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2)
predict(ModelQ1, DataA)
DataA <- data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2, cell = NA)
predict(ModelQ1, DataA)
DataA <- data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2, Cell = NA)
predict(ModelQ1, DataA)
View(inTrain)
View(inTrain)
rm(inTrain)
3:119
c(3:119)
training <- segmentationOriginal[segmentationOriginal$Case == "Train",c(3:19)]
testing <- segmentationOriginal[segmentationOriginal$Case == "Test",c(3:119)]
set.seed(125)
ModelQ1 <- train(Class~., data=training, method = "rpart")
DataA <- data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2)
predict(ModelQ1, DataA)
DataX <- testing[1,]
View(DataX)
DataX <- rep(NA,119)
DataX <- testing[1,]
for(i in 1:119){
DataX[1,i] <- NA
}
View(DataX)
DataA <- DataX
DataA$TotalIntenCh2[1] <- 23000
DataA <- DataX
DataA$TotalIntenCh2[1] <- 23000
DataA$FiberWidthCh1[1] <- 10
DataA$PerimStatusCh1 <- 2
predict(ModelQ1, DataA)
DataX <- testing[1:4,]
for(i in 1:119){
DataX[1,i] <- NA
DataX[2,i] <- NA
DataX[3,i] <- NA
DataX[4,i] <- NA
}
rm(DataA)
rm(DataB)
rm(DataC)
rm(DataD)
DataX <- testing[1:4,]
for(i in 1:119){
DataX[1,i] <- NA
DataX[2,i] <- NA
DataX[3,i] <- NA
DataX[4,i] <- NA
}
DataX$TotalIntenCh2[1] <- 23000
DataX$FiberWidthCh1[1] <- 10
DataX$PerimStatusCh1[1] <- 2
DataX$TotalIntenCh2[2] <- 50000
DataX$FiberWidthCh1[2] <- 10
DataX$VarIntenCh4[2] <- 100
DataX$TotalIntenCh2[3] <- 57000
DataX$FiberWidthCh1[3] <- 8
DataX$VarIntenCh4[3] <- 100
DataX$FiberWidthCh1[4] <- 8
DataX$VarIntenCh4[4] <- 100
DataX$PerimStatusCh1[4] <- 2
predict(ModelQ1, DataX)
a <- predict(ModelQ1, DataX)
a
?segmentationOriginal
a <- predict(ModelQ1, training)
a
a == testing$Class
training <- segmentationOriginal[segmentationOriginal$Case == "Train",c(3:119)]
testing <- segmentationOriginal[segmentationOriginal$Case == "Test",c(3:119)]
set.seed(125)
ModelQ1 <- train(Class~., data=training, method = "rpart")
DataX <- testing[1:4,]
for(i in 1:119){
DataX[1,i] <- NA
DataX[2,i] <- NA
DataX[3,i] <- NA
DataX[4,i] <- NA
}
DataX$TotalIntenCh2[1] <- 23000
DataX$FiberWidthCh1[1] <- 10
DataX$PerimStatusCh1[1] <- 2
DataX$TotalIntenCh2[2] <- 50000
DataX$FiberWidthCh1[2] <- 10
DataX$VarIntenCh4[2] <- 100
DataX$TotalIntenCh2[3] <- 57000
DataX$FiberWidthCh1[3] <- 8
DataX$VarIntenCh4[3] <- 100
DataX$FiberWidthCh1[4] <- 8
DataX$VarIntenCh4[4] <- 100
DataX$PerimStatusCh1[4] <- 2
a <- predict(ModelQ1, DataX)
a
predict(ModelQ1, testing)
a <- predict(ModelQ1, testing)
length(a)
a <- predict(ModelQ1, testing[1,])
length(a)
a <- predict(ModelQ1, testing[1:200,])
length(a)
a <- predict(ModelQ1, testing[1:1009,])
length(a)
a <- predict(ModelQ1, testing)
length(a)
a <- predict(ModelQ)
a <- predict(ModelQ1, DataX)
a
View(DataX)
DataX$TotalIntenCh4
DataX$TotalIntenCh2
DataX$VarIntenCh4
plot(ModelQ1)
ModelQ1
ModelQ1$finalModel
getTree(ModelQ1, k=1)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
ModelQ3 <- train(Area~., data=olive, method="tree")
ModelQ3 <- train(Area~., data=olive, method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
predict(ModelQ3, newdata)
class(olive$Area)
ModelQ3$finalModel
library(pgmm)
data(olive)
olive = olive[,-1]
ModelQ3 <- train(Area~., data=olive, method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
predict(ModelQ3, newdata)
ModelQ3$finalModel
?tree
install.packages("tree")
library("tree", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
?tree
library(pgmm)
data(olive)
olive = olive[,-1]
library(tree)
ModelQ3 <- tree(Area~., data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(ModelQ3, newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
View(trainSA)
?SAheart
View(SAheart)
set.seed(13234)
ModelQ4 <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, method ="glm", family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predict(ModelQ4, trainSA)
missClass(trainSA$chd,predict(ModelQ4, trainSA))
missClass(trainSA$chd,predict(ModelQ4, testSA))
missClass(testSA$chd,predict(ModelQ4, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
View(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
ModelQ5 <- train(yËœ., data=vowel.train, method="rf")
set.seed(33833)
ModelQ5 <- train(y~., data=vowel.train, method="rf")
?varImp
varImp(ModelQ5)
set.seed(33833)
ModelQ5 <- train(y~., data=vowel.train, method="rf")
VarImp(ModelQ5)
varImp(ModelQ5)
varImp(ModelQ5, useModel = TRUE)
importance(ModelQ5)
?randomForest
ModelQ5.b <- randomForest(y~., data=vowel.train)
importance(ModelQ5.b)
importance(ModelQ5.b, type=2)
set.seed(33833)
ModelQ5.b <- randomForest(y~., data=vowel.train)
importance(ModelQ5.b, type=2)
impQ5 <- importance(ModelQ5.b, type=2)
View(impQ5)
?sort
sort(impQ5[,2])
sort(impQ5)
sort(impQ5, decreasing = TRUE)
impQ5[sort(impQ5,decreasing=TRUE)]
?order
varImp(ModelQ5.b)
?sort
sort(impQ5,decreasing=TRUE,index.return=TRUE)
sort(impQ5,decreasing=TRUE,index.return=TRUE)$ix
impQ5[sort(impQ5,decreasing=TRUE,index.return=TRUE)$ix]
setwd("~/ownCloud/Practical Machine Learning/Week 3/Project")
training <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
testing <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
View(training)
table(training$username)
hist(training$username)
training$classe
names(training)
hist(training$user_name)
table(training$user_name)
table(training$classe)
names(testing)
testing$problem_id
set.seed(1512)
inTrain <- createDataPartition(data, p=0.75, list=FALSE)
training <- data[inTrain]
testing <- data[-inTrain]
data <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
set.seed(1512)
inTrain <- createDataPartition(data, p=0.75, list=FALSE)
training <- data[inTrain]
testing <- data[-inTrain]
assignment <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
inTrain <- createDataPartition(data, p=0.75, list=FALSE)
library(caret)
inTrain <- createDataPartition(data, p=0.75, list=FALSE)
setwd("~/ownCloud/Practical Machine Learning/Week 3/Project")
library(caret)
data <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
set.seed(1512)
inTrain <- createDataPartition(data, p=0.75, list=FALSE)
training <- data[inTrain,]
testing <- data[-inTrain,]
assignment <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
?createDataPartition
inTrain <- createDataPartition(data$classes, p=0.75, list=FALSE)
View(data)
set.seed(1512)
inTrain <- createDataPartition(data$classe, p=0.75, list=FALSE)
training <- data[inTrain,]
testing <- data[-inTrain,]
View(training)
nzv <- nearZeroVar(training, saveMetrics = TRUE)
View(nzv)
sum(nzv$nzv)
table(training$new_window)
table(testing$new_window)
View(training)
nzv <- nearZeroVar(training[training$new_window=="no"], saveMetrics = TRUE)
nzv <- nearZeroVar(training[training$new_window=="no",], saveMetrics = TRUE)
View(nzv)
sum(nzv$nzv)
160-101
nzv$nzv==nzv$zeroVar
sum(nzv$nzv==nzv$zeroVar)
setwd("~/ownCloud/Practical Machine Learning/Week 3/Project")
library(caret)
data <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data2 <- data[data$new_window == "no"]
set.seed(1512)
inTrain <- createDataPartition(data2$classe, p=0.75, list=FALSE)
training <- data[inTrain,]
testing <- data[-inTrain,]
assignment <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
nzv <- nearZeroVar(training[training$new_window=="no",], saveMetrics = TRUE)
setwd("~/ownCloud/Practical Machine Learning/Week 3/Project")
library(caret)
data <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
data2 <- data[data$new_window == "no",]
set.seed(1512)
inTrain <- createDataPartition(data2$classe, p=0.75, list=FALSE)
training <- data[inTrain,]
testing <- data[-inTrain,]
assignment <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)
nzv <- nearZeroVar(training[training$new_window=="no",], saveMetrics = TRUE)
View(nzv)
training_clean <- training[,-nzv$zeroVar]
nzv$zeroVar
-nzv$zeroVar
View(training_clean)
!nzv$zeroVar
training_clean <- training[,!nzv$zeroVar]
View(training_clean)
training_clean <- training_clean[,7:59]
View(training_clean)
Model1 <- train(classe~., method="rf",data=training_clean)
warnings()
class(training_clean$roll_belt)
classess <- rep("",53)
for(i in 1:53){
classess[i] <- class(training_clean[,i])
}
classess
Model1 <- train(classe~., data=training_clean, method="rf", prox=TRUE)
Model1<- randomForest(classe~., data=training_clean)
training_clean$classe <- as.factor(training_clean$classe)
classess <- rep("",53)
for(i in 1:53){
classess[i] <- class(training_clean[,i])
}
classess
Model1 <- train(classe~., data=training_clean, method="rf", prox=TRUE)
Model1 <- train(classe~., data=training_clean, method="rf")
Model1<- randomForest(classe~., data=training_clean)
plot(Model1)
Model1$importance
varImpPlot(Model1)
MDSplot(Model1, training$classe)
